{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: HTTP Error 405: Not allowed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "#stopword corpus to remove stopwords from sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "document1=pd.read_csv(\"spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document1.head()\n",
    "\n",
    "#data from kaggle spam-ham competition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\propylon\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "document2 = np.array(document1)  #convert array to numpy type array\n",
    "#split data into test train\n",
    "x_train ,x_test = train_test_split(document2,test_size=0.3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>There is a first time for everything :)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call 4 rude chat pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>God created gap btwn ur fingers so dat sum1 vr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>I am not having her number sir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ummma.will call after check in.our life will b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1    2    3    4\n",
       "0   ham            There is a first time for everything :)  NaN  NaN  NaN\n",
       "1  spam  Not heard from U4 a while. Call 4 rude chat pr...  NaN  NaN  NaN\n",
       "2   ham  God created gap btwn ur fingers so dat sum1 vr...  NaN  NaN  NaN\n",
       "3   ham                     I am not having her number sir  NaN  NaN  NaN\n",
       "4   ham  Ummma.will call after check in.our life will b...  NaN  NaN  NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2=pd.DataFrame(x_train)\n",
    "doc3=pd.DataFrame(x_test)\n",
    "doc2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#converting sentences for every input in form of tokens , every word would represent a token\n",
    "tokenizer = RegexpTokenizer(r'\\w+') #removes punctuations\n",
    "spam=[]\n",
    "ham=[]\n",
    "for index, row in doc2.iterrows():\n",
    "    if row[0]=='spam':\n",
    "        #converted all the words to lowercase\n",
    "        spam.append(tokenizer.tokenize(row[1].lower())) #spam list of sentences\n",
    "    if row[0]=='ham':\n",
    "        ham.append(tokenizer.tokenize(row[1].lower())) #ham \n",
    "test_dataset=[]\n",
    "test_label=[]\n",
    "for index, row in doc3.iterrows():\n",
    "    test_dataset.append(tokenizer.tokenize(row[1].lower())) #test dataset\n",
    "    test_label.append(tokenizer.tokenize(row[0].lower())) #test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\propylon\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\propylon\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:12: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13482 9713\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#stopwords corpus which we downloaded initially\n",
    "def flatted_list(texted):\n",
    "    return [item for sublist in texted for item in sublist]\n",
    "# creating spam and ham list of words appearing in the respective inputs\n",
    "spam_flat=flatted_list(spam)\n",
    "ham_flat=flatted_list(ham)\n",
    "#creating flat list of spam and ham\n",
    "\n",
    "#removing stopwords from spam and ham list\n",
    "spam_flat1=[word for word in spam_flat if word not in stopwords.words('english')] \n",
    "ham_flat1=[word for word in ham_flat if word not in stopwords.words('english')]\n",
    "print len(spam_flat),len(spam_flat1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "total=len(spam)+len(ham) #total number of training sentences\n",
    "#prior probabilities\n",
    "spam_prob=len(spam)/float(total) \n",
    "ham_prob=len(ham)/float(total) \n",
    "\n",
    "import nltk \n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "#can also create bigram, ngram words # but used unigram from simplification \n",
    "#Freqdist counts a particular word appearing in the corpus\n",
    "\n",
    "def unigram(word):\n",
    "    # Write your code here.\n",
    "    fdist1=FreqDist(word)\n",
    "    return fdist1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_uni=unigram(spam_flat1) #calculate count of any word/ similarly can be done for bigrams/ngrams\n",
    "#print spam_uni[('win')]\n",
    "ham_uni=unigram(ham_flat1)\n",
    "#print ham_uni[(['happy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\propylon\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:6: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict_labels=[]\n",
    "for i,sentence in enumerate(test_dataset):\n",
    "    ham_bayes=ham_prob #prior prob\n",
    "    spam_bayes=spam_prob\n",
    "    sentence1=[word for word in sentence if word not in stopwords.words('english')]\n",
    "    #removing stopwords from test data\n",
    "    for k,word in enumerate(sentence1):\n",
    "        #laplacian and prob(word/spam) \n",
    "        spam_pro=float(spam_uni[word]+1)/float(len(spam_flat1)+1)\n",
    "        #prob(word/ham)\n",
    "        ham_pro=float(ham_uni[word]+1)/float(len(ham_flat1)+1)\n",
    "        #naive bayes calculation , gets multiplied with every loop \n",
    "        spam_bayes=spam_bayes*spam_pro\n",
    "        ham_bayes=ham_bayes*ham_pro\n",
    "    #normalizing the values    \n",
    "    normalized_spam=float(spam_bayes)/float(spam_bayes+ham_bayes)\n",
    "    normalized_ham=float(ham_bayes)/float(spam_bayes+ham_bayes)\n",
    "    #predicting whether the sentence is spam or ham, based on the normalized values\n",
    "    if normalized_spam>normalized_ham:\n",
    "        predict_labels.append('spam')\n",
    "    else:\n",
    "        predict_labels.append('ham')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9539198084979055"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=0\n",
    "for i1 in range(len(test_label)):\n",
    "    if test_label[i1][0]==predict_labels[i1]:\n",
    "        acc=acc+1\n",
    "float(acc)/float(i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
